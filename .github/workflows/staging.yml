name: Staging - Build and Deploy Site

on:
  push:
    branches:
      - staging

jobs:
  build-and-deploy-site:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
        with:
          submodules: true
          fetch-depth: 0

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v3
        with:
          hugo-version: 'latest'
          extended: true

      - name: Build site with Hugo
        run: hugo --minify --baseURL="${{ secrets.STAGING_DOMAIN }}"

      - name: Check HTML
        uses: chabad360/htmlproofer@master
        with:
          directory: "./public"
          arguments: --only-4xx --check-favicon --check-html --assume-extension --empty-alt-ignore --disable-external
        continue-on-error: true

      - name: Add a robots.txt to disallow crawling staging
        run: |
          cat > ./public/robots.txt <<EOF
          User-agent: *
          Disallow: /

          EOF
      - name: FTP Deployer
        uses: sand4rt/ftp-deployer@v1.7
        with:
          sftp: true # optional
          host: ${{ secrets.SFTP_SERVER }} # e.g. ftp.host.com or sftp.host.com (without ftp:// or ftps://)
          port: 22 # optional, default is: 21
          username: ${{ secrets.SFTP_USERNAME }} # FTP username
          password: ${{ secrets.SFTP_PASSWORD }} # FTP password
          remote_folder: ${{ secrets.SFTP_REMOTE_PATH }} # optional, remote path of your FTP server
          local_folder: ./public # optional, local path, default is: dist
          cleanup: true # optional, remove existing files inside FTP remote folder
          include: '["**/*"]' # optional, e.g. '['dist']'
          exclude: '[]' # optional, e.g. '['node_modules/**', '.git/**', '*.env']'
