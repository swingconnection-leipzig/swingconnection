name: Staging - Build and Deploy Site

on:
  push:
    branches:
      - staging

jobs:
  build-and-deploy-site:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
        with:
          submodules: true
          fetch-depth: 0

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v3
        with:
          hugo-version: 'latest'
          extended: true

      - name: Build site with Hugo
        run: hugo --minify --baseURL="${{ secrets.STAGING_DOMAIN }}"

      - name: Check HTML
        uses: chabad360/htmlproofer@master
        with:
          directory: "./public"
          arguments: --only-4xx --check-favicon --check-html --assume-extension --empty-alt-ignore --disable-external
        continue-on-error: true

      - name: Add a robots.txt to disallow crawling staging
        run: |
          cat > ./public/robots.txt <<EOF
          User-agent: *
          Disallow: /

          EOF

      - name: Install rsync and sshpass
        run: |
          sudo apt-get update -y
          sudo apt-get install -y rsync sshpass

      - name: Deploy via rsync
        run: |
          sshpass -p '${{ secrets.SSH_PASSWORD }}' rsync -avz --no-times --no-perms --delete -e "ssh -o StrictHostKeyChecking=no" \
            public/ \
            ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }}:${{ SSH_REMOTE_BASE_PATH }}/staging
